{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openpyxl\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.py', 'amazon_reviews.csv', 'IMDB_Dataset.xlsx']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"../Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df = pd.read_excel(\"../Datasets/IMDB_Dataset.xlsx\")\n",
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1114</td>\n",
       "      <td>1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                                1114      1114\n",
       "unique                                               1114         2\n",
       "top     One of the other reviewers has mentioned that ...  positive\n",
       "freq                                                    1       558"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    558\n",
       "negative    556\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text Normalization \n",
    "# 1. Removing Stop words\n",
    "\n",
    "stop_words_list = nltk.corpus.stopwords.words('english')\n",
    "stop_words_list[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Removing html strips  and punctuations\n",
    "import string\n",
    "\n",
    "exclude_list = string.punctuation\n",
    "\n",
    "def strip_html(text):\n",
    "    bsp = BeautifulSoup(text,\"html.parser\")\n",
    "    return bsp.get_text()\n",
    "\n",
    "def remove_punc(text):\n",
    "    for char in exclude_list:\n",
    "        txt = text.replace(char,\"\")\n",
    "    return txt\n",
    "\n",
    "\n",
    "def remove_noise_data(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_punc(text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['review_clean'] = imdb_df['review'].apply(remove_noise_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "                                        review_clean  \n",
       "0  One of the other reviewers has mentioned that ...  \n",
       "1  A wonderful little production. The filming tec...  \n",
       "2  I thought this was a wonderful way to spend ti...  \n",
       "3  Basically there's a family where a little boy ...  \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  \n",
       "5  Probably my all-time favorite movie, a story o...  \n",
       "6  I sure would like to see a resurrection of a u...  \n",
       "7  This show was an amazing, fresh & innovative i...  \n",
       "8  Encouraged by the positive comments about this...  \n",
       "9  If you like original gut wrenching laughter yo...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming \n",
    "    * Its process of reducing word to its word stem\n",
    "    * eg: we have review as \"eating,eat,eaten \",all these words refers to same so we no need to have all these words instead of that just have one word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def stem_review(text):\n",
    "    # Initialize the Lemmatizer\n",
    "    lt = WordNetLemmatizer()\n",
    "\n",
    "    # Tokenize and lemmatize each word\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lt.lemmatize(word,pos='v') for word in tokens]\n",
    "\n",
    "    text = ' '.join(lemmatized_tokens)\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['review_clean_v1'] = imdb_df['review_clean'].apply(stem_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_clean_v1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>One of the other reviewers have mention that a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>A wonderful little production . The film techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>I think this be a wonderful way to spend time ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>Basically there 's a family where a little boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>Petter Mattei 's `` Love in the Time of Money ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Probably my all-time favorite movie, a story o...</td>\n",
       "      <td>Probably my all-time favorite movie , a story ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "      <td>I sure would like to see a resurrection of a u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>negative</td>\n",
       "      <td>This show was an amazing, fresh &amp; innovative i...</td>\n",
       "      <td>This show be an amaze , fresh &amp; innovative ide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Encouraged by the positive comments about this...</td>\n",
       "      <td>Encouraged by the positive comment about this ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>positive</td>\n",
       "      <td>If you like original gut wrenching laughter yo...</td>\n",
       "      <td>If you like original gut wrench laughter you w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "5  Probably my all-time favorite movie, a story o...  positive   \n",
       "6  I sure would like to see a resurrection of a u...  positive   \n",
       "7  This show was an amazing, fresh & innovative i...  negative   \n",
       "8  Encouraged by the positive comments about this...  negative   \n",
       "9  If you like original gut wrenching laughter yo...  positive   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "5  Probably my all-time favorite movie, a story o...   \n",
       "6  I sure would like to see a resurrection of a u...   \n",
       "7  This show was an amazing, fresh & innovative i...   \n",
       "8  Encouraged by the positive comments about this...   \n",
       "9  If you like original gut wrenching laughter yo...   \n",
       "\n",
       "                                     review_clean_v1  \n",
       "0  One of the other reviewers have mention that a...  \n",
       "1  A wonderful little production . The film techn...  \n",
       "2  I think this be a wonderful way to spend time ...  \n",
       "3  Basically there 's a family where a little boy...  \n",
       "4  Petter Mattei 's `` Love in the Time of Money ...  \n",
       "5  Probably my all-time favorite movie , a story ...  \n",
       "6  I sure would like to see a resurrection of a u...  \n",
       "7  This show be an amaze , fresh & innovative ide...  \n",
       "8  Encouraged by the positive comment about this ...  \n",
       "9  If you like original gut wrench laughter you w...  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the pre-trained BERT tokenizer once\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    # Tokenize into sub words\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Remove stop words and punctuation and numbers in one go\n",
    "    tokens =[token.strip() for token in tokens if token not in stop_words_list and token not in string.punctuation and not token.isdigit()]\n",
    "\n",
    "    # Reassemble the tokens into a single string\n",
    "    text = ' '.join(tokens)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_df['review_clean_v2'] = imdb_df['review_clean_v1'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>review_clean_v1</th>\n",
       "      <th>review_clean_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>One of the other reviewers have mention that a...</td>\n",
       "      <td>one reviewers mention watch oz episode hook ri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>A wonderful little production . The film techn...</td>\n",
       "      <td>wonderful little production film technique una...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>I think this be a wonderful way to spend time ...</td>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>Basically there 's a family where a little boy...</td>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>Petter Mattei 's `` Love in the Time of Money ...</td>\n",
       "      <td>pet ##ter matt ##ei love time money visually s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                        review_clean  \\\n",
       "0  One of the other reviewers has mentioned that ...   \n",
       "1  A wonderful little production. The filming tec...   \n",
       "2  I thought this was a wonderful way to spend ti...   \n",
       "3  Basically there's a family where a little boy ...   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...   \n",
       "\n",
       "                                     review_clean_v1  \\\n",
       "0  One of the other reviewers have mention that a...   \n",
       "1  A wonderful little production . The film techn...   \n",
       "2  I think this be a wonderful way to spend time ...   \n",
       "3  Basically there 's a family where a little boy...   \n",
       "4  Petter Mattei 's `` Love in the Time of Money ...   \n",
       "\n",
       "                                     review_clean_v2  \n",
       "0  one reviewers mention watch oz episode hook ri...  \n",
       "1  wonderful little production film technique una...  \n",
       "2  think wonderful way spend time hot summer week...  \n",
       "3  basically family little boy jake think zombie ...  \n",
       "4  pet ##ter matt ##ei love time money visually s...  "
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "1    558\n",
      "0    556\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mention watch oz episode hook ri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production film technique una...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think wonderful way spend time hot summer week...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically family little boy jake think zombie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  one reviewers mention watch oz episode hook ri...          1\n",
       "1  wonderful little production film technique una...          1\n",
       "2  think wonderful way spend time hot summer week...          1\n",
       "3  basically family little boy jake think zombie ...          0"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "final_imdb = imdb_df[['review_clean_v2','sentiment']]\n",
    "final_imdb.columns = ['review','sentiment']\n",
    "\n",
    "final_imdb['sentiment'] = final_imdb['sentiment'].map({'positive':1,'negative':0,'neutral':2})\n",
    "print(final_imdb['sentiment'].value_counts())\n",
    "final_imdb.head(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       object\n",
       "sentiment     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_imdb.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide Train and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891,) (223,) (891,) (223,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(final_imdb['review'],final_imdb['sentiment'],test_size=0.2,random_state=42)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets start Embedding Models\n",
    "## 1. Bag of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    {'acc': 1, 'agenda': 1, 'agreements': 1, 'appe...\n",
       "1    {'actors': 1, 'bbc': 1, 'chosen': 1, 'come': 1...\n",
       "2    {'ada': 1, 'addiction': 1, 'air': 1, 'allen': ...\n",
       "Name: bow, dtype: object"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def bow(text):\n",
    "    cv = CountVectorizer()\n",
    "\n",
    "    #  Fit the model and transform the documents to a Bag of Words representation\n",
    "    bow = cv.fit_transform([text]) #Input should be iterable so we making it as list\n",
    "\n",
    "    # Convert the sparse matrix to an array and return it\n",
    "    return dict(zip(cv.get_feature_names_out(),  bow.toarray()[0]))\n",
    "\n",
    "\n",
    "imdb_df['bow'] = imdb_df['review_clean_v2'].apply(bow)\n",
    "imdb_df['bow'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381     1\n",
       "327     0\n",
       "998     0\n",
       "959     0\n",
       "582     1\n",
       "       ..\n",
       "466     1\n",
       "121     1\n",
       "1044    1\n",
       "1095    0\n",
       "860     1\n",
       "Name: sentiment, Length: 891, dtype: int64"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "879     largely forget ##table tale mercenary kerman e...\n",
       "101     okay last night august 18th distinct displeasu...\n",
       "1111    saw movie ##s years ago literally sweep away c...\n",
       "726     tv series one ones love kid even though see pi...\n",
       "291     reservations movie figure would usual bill far...\n",
       "                              ...                        \n",
       "184     ordinary made tv product tyson attempt serious...\n",
       "875     let first say believer ghost indeed know exist...\n",
       "507     animation simple straightforward good vs evil ...\n",
       "722     hear driving lessons itv ad ##vert honest n kn...\n",
       "583     art film either make national film preservatio...\n",
       "Name: review, Length: 223, dtype: object"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_features=500: Limits the number of features to the top 500 most frequent words.\n",
    "# stop_words='english': This removes common English stop words like \"the\", \"and\", \"is\", etc.\n",
    "\n",
    "cv = CountVectorizer(stop_words='english', max_features=500)\n",
    "x_train_bow = cv.fit_transform(X_train) # Learn the vocabulary and transform training data into vectors\n",
    "\n",
    "x_train_bow.toarray()\n",
    "\n",
    "x_test_bow = cv.transform(X_test) #  Transform the test data using the same vocabulary (without fitting again)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]]\n",
      "['ab' 'able' 'absolutely' 'act' 'action' 'actor' 'actors' 'actress'\n",
      " 'actual' 'actually' 'ad' 'add' 'age' 'al' 'alien' 'allow' 'ama'\n",
      " 'american' 'animation' 'ann' 'apparently' 'appear' 'art' 'ask' 'ate'\n",
      " 'attempt' 'audience' 'away' 'awful' 'bad' 'base' 'beautiful' 'begin'\n",
      " 'bel' 'believe' 'best' 'better' 'big' 'bite' 'black' 'ble' 'blood' 'bo'\n",
      " 'body' 'book' 'bore' 'box' 'boy' 'brain' 'break' 'brilliant' 'bring'\n",
      " 'budget' 'buy' 'ca' 'camera' 'car' 'care' 'case' 'cast' 'catch' 'cause'\n",
      " 'certainly' 'chance' 'change' 'character' 'che' 'child' 'children'\n",
      " 'cinema' 'city' 'cl' 'class' 'classic' 'close' 'com' 'come' 'comedy'\n",
      " 'comment' 'complete' 'completely' 'confuse' 'consider' 'cool' 'cop'\n",
      " 'country' 'couple' 'course' 'cr' 'create' 'credit' 'cut' 'da' 'dan'\n",
      " 'dark' 'day' 'days' 'dead' 'deal' 'death' 'decent' 'decide' 'definitely'\n",
      " 'deliver' 'deserve' 'despite' 'di' 'dialogue' 'die' 'different' 'direct'\n",
      " 'direction' 'director' 'dr' 'drama' 'dream' 'drug' 'dvd' 'early' 'earth'\n",
      " 'ed' 'effect' 'em' 'en' 'end' 'enjoy' 'entertain' 'entire' 'episode' 'er'\n",
      " 'ers' 'es' 'especially' 'evil' 'ex' 'example' 'excellent' 'expect'\n",
      " 'experience' 'explain' 'extremely' 'ey' 'eye' 'face' 'fact' 'fail' 'fall'\n",
      " 'family' 'fan' 'fantastic' 'far' 'father' 'favorite' 'feature' 'feel'\n",
      " 'felt' 'fi' 'fight' 'film' 'finally' 'fine' 'flick' 'follow' 'force'\n",
      " 'forget' 'friend' 'friends' 'ful' 'fun' 'funny' 'ga' 'game' 'genre'\n",
      " 'girl' 'girls' 'god' 'good' 'gore' 'gr' 'grade' 'great' 'group' 'guess'\n",
      " 'guy' 'ha' 'half' 'hand' 'happen' 'hard' 'head' 'hear' 'heart' 'hell'\n",
      " 'help' 'high' 'history' 'hit' 'ho' 'hold' 'hollywood' 'home' 'hope'\n",
      " 'horror' 'hot' 'house' 'huge' 'human' 'humor' 'ic' 'ich' 'idea' 'im'\n",
      " 'imp' 'important' 'include' 'ing' 'ins' 'instead' 'int' 'involve' 'ish'\n",
      " 'ize' 'jack' 'job' 'john' 'joke' 'ka' 'ki' 'kid' 'kill' 'killer' 'kind'\n",
      " 'know' 'la' 'lack' 'land' 'late' 'later' 'laugh' 'le' 'lead' 'learn'\n",
      " 'leave' 'let' 'level' 'li' 'lie' 'life' 'light' 'like' 'line' 'little'\n",
      " 'live' 'lo' 'long' 'look' 'lose' 'lot' 'love' 'low' 'lu' 'ly' 'main'\n",
      " 'make' 'man' 'manage' 'matter' 'maybe' 'mean' 'meet' 'men' 'mention'\n",
      " 'message' 'michael' 'middle' 'mind' 'minutes' 'mis' 'miss' 'mo' 'moments'\n",
      " 'money' 'mother' 'movie' 'movies' 'mr' 'mu' 'murder' 'music' 'na' 'ne'\n",
      " 'need' 'ness' 'new' 'ni' 'nice' 'night' 'note' 'nt' 'number' 'offer' 'og'\n",
      " 'oh' 'oint' 'ok' 'old' 'ones' 'open' 'order' 'original' 'oscar' 'ous'\n",
      " 'overall' 'parent' 'particular' 'pay' 'people' 'perfect' 'performance'\n",
      " 'performances' 'person' 'pick' 'picture' 'piece' 'pl' 'place' 'play'\n",
      " 'plot' 'point' 'police' 'poor' 'portray' 'power' 'pp' 'pre' 'present'\n",
      " 'pretty' 'probably' 'problem' 'production' 'pull' 'quality' 'quite' 'ra'\n",
      " 'rat' 'rate' 'read' 'real' 'reality' 'realize' 'really' 'reason'\n",
      " 'recommend' 'red' 'release' 'remain' 'remember' 'rent' 'rest' 'review'\n",
      " 'ridiculous' 'right' 'rock' 'role' 'roles' 'romance' 'romantic' 'room'\n",
      " 'run' 'sa' 'sad' 'save' 'saw' 'say' 'sc' 'scene' 'scenes' 'school' 'sci'\n",
      " 'score' 'screen' 'script' 'se' 'second' 'self' 'sen' 'sense' 'sequence'\n",
      " 'series' 'set' 'sex' 'sh' 'shoot' 'short' 'simply' 'sing' 'sit' 'sl'\n",
      " 'slow' 'small' 'son' 'song' 'soon' 'sort' 'sound' 'sp' 'space' 'speak'\n",
      " 'special' 'spoil' 'st' 'stand' 'star' 'start' 'stay' 'stick' 'stop'\n",
      " 'stories' 'story' 'strong' 'stupid' 'style' 'su' 'sub' 'support'\n",
      " 'suppose' 'sure' 'surprise' 'talk' 'te' 'team' 'television' 'tell'\n",
      " 'terrible' 'thank' 'theme' 'thing' 'things' 'think' 'throw' 'ti' 'time'\n",
      " 'title' 'today' 'tom' 'totally' 'touch' 'town' 'train' 'true' 'truly'\n",
      " 'truth' 'try' 'turn' 'tv' 'twist' 'type' 'typical' 'understand'\n",
      " 'unfortunately' 'use' 'vable' 've' 'version' 'video' 'view' 'viewer'\n",
      " 'violence' 'voice' 'wait' 'walk' 'want' 'war' 'waste' 'watch' 'way'\n",
      " 'weird' 'white' 'wife' 'win' 'wish' 'wo' 'woman' 'women' 'wonder'\n",
      " 'wonderful' 'word' 'work' 'world' 'worse' 'worst' 'worth' 'write'\n",
      " 'writer' 'wrong' 'year' 'years' 'yes' 'young' 'ze']\n"
     ]
    }
   ],
   "source": [
    "print(x_train_bow.toarray())\n",
    "print(cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 500)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_bow.shape # as we have taken max_features =500 so it had created with 500 dimension vector using BOW technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223, 500)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Apply Naive Bayes Model\n",
    "    * Naive Bayes is good for text classification like sentiment analysis when we are working on BOW and TF-DIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.8610\n",
      "classification_report ....\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.91      0.87       111\n",
      "           1       0.90      0.81      0.85       112\n",
      "\n",
      "    accuracy                           0.86       223\n",
      "   macro avg       0.86      0.86      0.86       223\n",
      "weighted avg       0.86      0.86      0.86       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes Model for prediction\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "# Train a classifier (Naive Bayes)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(x_train_bow,y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = nb_model.predict(x_test_bow)\n",
    "\n",
    "#Evaluate the Model\n",
    "print(f\"accuracy_score is {accuracy_score(y_test,y_pred):.4f}\")\n",
    "print(\"classification_report ....\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Apply Xgboost on BOW\n",
    "    * Gradient Boosting methods (like XGBoost) can often outperform simpler models but are computationally more expensive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.7982\n",
      "classification_report ....\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.78      0.79       111\n",
      "           1       0.79      0.81      0.80       112\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.80      0.80      0.80       223\n",
      "weighted avg       0.80      0.80      0.80       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "xgb_model.fit(x_train_bow,y_train)\n",
    "y_pred = xgb_model.predict(x_test_bow)\n",
    "#Evaluate the Model\n",
    "print(f\"accuracy_score is {accuracy_score(y_test,y_pred):.4f}\")\n",
    "print(\"classification_report ....\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Apply Support Vector Machine (SVM) on BOW\n",
    "    * SVM is often a strong choice for text classification. It works well in high-dimensional spaces (such as those in text data) and can handle both linear and non-linear classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score is 0.7758\n",
      "classification_report ....\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.83      0.79       111\n",
      "           1       0.81      0.72      0.76       112\n",
      "\n",
      "    accuracy                           0.78       223\n",
      "   macro avg       0.78      0.78      0.78       223\n",
      "weighted avg       0.78      0.78      0.78       223\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='linear')  # Linear kernel is usually preferred for text classification\n",
    "svm_model.fit(x_train_bow,y_train)\n",
    "y_pred = svm_model.predict(x_test_bow)\n",
    "\n",
    "#Evaluate the Model\n",
    "print(f\"accuracy_score is {accuracy_score(y_test,y_pred):.4f}\")\n",
    "print(\"classification_report ....\")\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(txt):\n",
    "   # Here we are doing all pre processing steps such as stop words, digits, stemming etc\n",
    "   txt = remove_stop_words(txt)\n",
    "   txt = stem_review(txt)\n",
    "   return txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-8 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-8 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-8 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-8 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-8 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-8 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-8 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-8 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-8 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-8 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=500, stop_words=&#x27;english&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;CountVectorizer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\">?<span>Documentation for CountVectorizer</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>CountVectorizer(max_features=500, stop_words=&#x27;english&#x27;)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_features=500, stop_words='english')"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prediction with new data\n",
    "\n",
    "def predict_analysis(txt):\n",
    "    # Step 1. Do Pre Process\n",
    "    txt = pre_process(txt)\n",
    "    print(f\"after process {txt}\")\n",
    "\n",
    "    # Step 2: Apply BOW Technique to create Vector/Embeddings\n",
    "    X = cv.transform([txt])\n",
    "    vector = X.toarray() # Converting vector to dense format\n",
    "    print(f\"vector for given sentence is {vector}\")\n",
    "    vocab = cv.get_feature_names_out() # it will return top 500 feature names which is trained on CountVectorizer\n",
    "    print(f\"vocab of BOW is {vocab}\")\n",
    "\n",
    "    # Step 3: Now its time to evaluate with unknown data and predict it.\n",
    "\n",
    "    sentiment_dict = {1:'positive',0:'negative',2:'neutral'}\n",
    "    \n",
    "\n",
    "    pred = nb_model.predict(vector)\n",
    "    print('prediction result is ...................')\n",
    "    print(f\"Pred is {sentiment_dict[pred[0]]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after process let first say believer ghost indeed know exist\n",
      "vector for given sentence is [[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "vocab of BOW is ['ab' 'able' 'absolutely' 'act' 'action' 'actor' 'actors' 'actress'\n",
      " 'actual' 'actually' 'ad' 'add' 'age' 'al' 'alien' 'allow' 'ama'\n",
      " 'american' 'animation' 'ann' 'apparently' 'appear' 'art' 'ask' 'ate'\n",
      " 'attempt' 'audience' 'away' 'awful' 'bad' 'base' 'beautiful' 'begin'\n",
      " 'bel' 'believe' 'best' 'better' 'big' 'bite' 'black' 'ble' 'blood' 'bo'\n",
      " 'body' 'book' 'bore' 'box' 'boy' 'brain' 'break' 'brilliant' 'bring'\n",
      " 'budget' 'buy' 'ca' 'camera' 'car' 'care' 'case' 'cast' 'catch' 'cause'\n",
      " 'certainly' 'chance' 'change' 'character' 'che' 'child' 'children'\n",
      " 'cinema' 'city' 'cl' 'class' 'classic' 'close' 'com' 'come' 'comedy'\n",
      " 'comment' 'complete' 'completely' 'confuse' 'consider' 'cool' 'cop'\n",
      " 'country' 'couple' 'course' 'cr' 'create' 'credit' 'cut' 'da' 'dan'\n",
      " 'dark' 'day' 'days' 'dead' 'deal' 'death' 'decent' 'decide' 'definitely'\n",
      " 'deliver' 'deserve' 'despite' 'di' 'dialogue' 'die' 'different' 'direct'\n",
      " 'direction' 'director' 'dr' 'drama' 'dream' 'drug' 'dvd' 'early' 'earth'\n",
      " 'ed' 'effect' 'em' 'en' 'end' 'enjoy' 'entertain' 'entire' 'episode' 'er'\n",
      " 'ers' 'es' 'especially' 'evil' 'ex' 'example' 'excellent' 'expect'\n",
      " 'experience' 'explain' 'extremely' 'ey' 'eye' 'face' 'fact' 'fail' 'fall'\n",
      " 'family' 'fan' 'fantastic' 'far' 'father' 'favorite' 'feature' 'feel'\n",
      " 'felt' 'fi' 'fight' 'film' 'finally' 'fine' 'flick' 'follow' 'force'\n",
      " 'forget' 'friend' 'friends' 'ful' 'fun' 'funny' 'ga' 'game' 'genre'\n",
      " 'girl' 'girls' 'god' 'good' 'gore' 'gr' 'grade' 'great' 'group' 'guess'\n",
      " 'guy' 'ha' 'half' 'hand' 'happen' 'hard' 'head' 'hear' 'heart' 'hell'\n",
      " 'help' 'high' 'history' 'hit' 'ho' 'hold' 'hollywood' 'home' 'hope'\n",
      " 'horror' 'hot' 'house' 'huge' 'human' 'humor' 'ic' 'ich' 'idea' 'im'\n",
      " 'imp' 'important' 'include' 'ing' 'ins' 'instead' 'int' 'involve' 'ish'\n",
      " 'ize' 'jack' 'job' 'john' 'joke' 'ka' 'ki' 'kid' 'kill' 'killer' 'kind'\n",
      " 'know' 'la' 'lack' 'land' 'late' 'later' 'laugh' 'le' 'lead' 'learn'\n",
      " 'leave' 'let' 'level' 'li' 'lie' 'life' 'light' 'like' 'line' 'little'\n",
      " 'live' 'lo' 'long' 'look' 'lose' 'lot' 'love' 'low' 'lu' 'ly' 'main'\n",
      " 'make' 'man' 'manage' 'matter' 'maybe' 'mean' 'meet' 'men' 'mention'\n",
      " 'message' 'michael' 'middle' 'mind' 'minutes' 'mis' 'miss' 'mo' 'moments'\n",
      " 'money' 'mother' 'movie' 'movies' 'mr' 'mu' 'murder' 'music' 'na' 'ne'\n",
      " 'need' 'ness' 'new' 'ni' 'nice' 'night' 'note' 'nt' 'number' 'offer' 'og'\n",
      " 'oh' 'oint' 'ok' 'old' 'ones' 'open' 'order' 'original' 'oscar' 'ous'\n",
      " 'overall' 'parent' 'particular' 'pay' 'people' 'perfect' 'performance'\n",
      " 'performances' 'person' 'pick' 'picture' 'piece' 'pl' 'place' 'play'\n",
      " 'plot' 'point' 'police' 'poor' 'portray' 'power' 'pp' 'pre' 'present'\n",
      " 'pretty' 'probably' 'problem' 'production' 'pull' 'quality' 'quite' 'ra'\n",
      " 'rat' 'rate' 'read' 'real' 'reality' 'realize' 'really' 'reason'\n",
      " 'recommend' 'red' 'release' 'remain' 'remember' 'rent' 'rest' 'review'\n",
      " 'ridiculous' 'right' 'rock' 'role' 'roles' 'romance' 'romantic' 'room'\n",
      " 'run' 'sa' 'sad' 'save' 'saw' 'say' 'sc' 'scene' 'scenes' 'school' 'sci'\n",
      " 'score' 'screen' 'script' 'se' 'second' 'self' 'sen' 'sense' 'sequence'\n",
      " 'series' 'set' 'sex' 'sh' 'shoot' 'short' 'simply' 'sing' 'sit' 'sl'\n",
      " 'slow' 'small' 'son' 'song' 'soon' 'sort' 'sound' 'sp' 'space' 'speak'\n",
      " 'special' 'spoil' 'st' 'stand' 'star' 'start' 'stay' 'stick' 'stop'\n",
      " 'stories' 'story' 'strong' 'stupid' 'style' 'su' 'sub' 'support'\n",
      " 'suppose' 'sure' 'surprise' 'talk' 'te' 'team' 'television' 'tell'\n",
      " 'terrible' 'thank' 'theme' 'thing' 'things' 'think' 'throw' 'ti' 'time'\n",
      " 'title' 'today' 'tom' 'totally' 'touch' 'town' 'train' 'true' 'truly'\n",
      " 'truth' 'try' 'turn' 'tv' 'twist' 'type' 'typical' 'understand'\n",
      " 'unfortunately' 'use' 'vable' 've' 'version' 'video' 'view' 'viewer'\n",
      " 'violence' 'voice' 'wait' 'walk' 'want' 'war' 'waste' 'watch' 'way'\n",
      " 'weird' 'white' 'wife' 'win' 'wish' 'wo' 'woman' 'women' 'wonder'\n",
      " 'wonderful' 'word' 'work' 'world' 'worse' 'worst' 'worth' 'write'\n",
      " 'writer' 'wrong' 'year' 'years' 'yes' 'young' 'ze']\n",
      "prediction result is ...................\n",
      "Pred is negative\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict_analysis(\"let first say believer ghost indeed know exist\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below case is to understand above example with small Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Fit the CountVectorizer on training data (this should be done before prediction)\n",
    "corpus = [\"The cat sat on the mat\", \"The dog barked at the cat\", \"Cats and dogs are friends\"]\n",
    "\n",
    "cv_bow = CountVectorizer(max_features=5)\n",
    "cv_bow.fit(corpus)  # Fit on the entire training corpus\n",
    "\n",
    "def pre_process(txt):\n",
    "    # Implement your pre-processing here (e.g., lowercasing, removing punctuation, etc.)\n",
    "    txt = txt.lower()\n",
    "    return txt\n",
    "\n",
    "def predict_analysis(txt):\n",
    "    # Step 1: Pre-process the input text\n",
    "    txt = pre_process(txt)\n",
    "    print(f\"After processing: {txt}\")\n",
    "\n",
    "    # Step 2: Transform the new text into a vector using the fitted CountVectorizer\n",
    "    X = cv_bow.transform([txt])\n",
    "    vector = X.toarray()\n",
    "    print(f\"Vector: {vector}\")\n",
    "\n",
    "    # Step 3: Get the vocabulary (feature names)\n",
    "    vocab = cv_bow.get_feature_names_out()\n",
    "    print(f\"Vocabulary: {vocab}\")\n",
    "\n",
    "    # If you have a prediction model (e.g., Naive Bayes)\n",
    "    # here we can start using ML Models for predictions similar to above IMDB Dataset example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we had mentioned max_features =5 so vector dimension will be 5 which takes most repeating words of top 5 from given corpus while doing train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After processing: cat is a pet\n",
      "Vector: [[0 0 0 1 0]]\n",
      "Vocabulary: ['and' 'are' 'at' 'cat' 'the']\n"
     ]
    }
   ],
   "source": [
    "predict_analysis(\"Cat is a pet\") # Note: in this small example, we did not apply much pre processing steps eg: stop words etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
