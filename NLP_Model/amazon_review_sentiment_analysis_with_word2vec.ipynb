{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openpyxl\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.py', 'amazon_reviews.csv', 'IMDB_Dataset.xlsx']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../Datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No issues.</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0mie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1K3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1m2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 reviewerName  overall  \\\n",
       "0           0          NaN      4.0   \n",
       "1           1         0mie      5.0   \n",
       "2           2          1K3      4.0   \n",
       "3           3          1m2      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  day_diff  \\\n",
       "0                                         No issues.  2014-07-23       138   \n",
       "1  Purchased this for my device, it worked as adv...  2013-10-25       409   \n",
       "2  it works as expected. I should have sprung for...  2012-12-23       715   \n",
       "3  This think has worked out great.Had a diff. br...  2013-11-21       382   \n",
       "\n",
       "   helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "0            0           0           0                   0   \n",
       "1            0           0           0                   0   \n",
       "2            0           0           0                   0   \n",
       "3            0           0           0                   0   \n",
       "\n",
       "   score_average_rating  wilson_lower_bound  \n",
       "0                   0.0                 0.0  \n",
       "1                   0.0                 0.0  \n",
       "2                   0.0                 0.0  \n",
       "3                   0.0                 0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv(\"../Datasets/amazon_reviews.csv\")\n",
    "review_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4915, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                int64\n",
       "reviewerName             object\n",
       "overall                 float64\n",
       "reviewText               object\n",
       "reviewTime               object\n",
       "day_diff                  int64\n",
       "helpful_yes               int64\n",
       "helpful_no                int64\n",
       "total_vote                int64\n",
       "score_pos_neg_diff        int64\n",
       "score_average_rating    float64\n",
       "wilson_lower_bound      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2457.000000</td>\n",
       "      <td>4.587589</td>\n",
       "      <td>437.367040</td>\n",
       "      <td>1.311089</td>\n",
       "      <td>0.210376</td>\n",
       "      <td>1.521465</td>\n",
       "      <td>1.100712</td>\n",
       "      <td>0.075468</td>\n",
       "      <td>0.020053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1418.982617</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>209.439871</td>\n",
       "      <td>41.619161</td>\n",
       "      <td>4.023296</td>\n",
       "      <td>44.123095</td>\n",
       "      <td>39.367949</td>\n",
       "      <td>0.256062</td>\n",
       "      <td>0.077187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-130.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1228.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2457.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3685.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4914.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1064.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1884.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      overall     day_diff  helpful_yes   helpful_no  \\\n",
       "count  4915.000000  4915.000000  4915.000000  4915.000000  4915.000000   \n",
       "mean   2457.000000     4.587589   437.367040     1.311089     0.210376   \n",
       "std    1418.982617     0.996845   209.439871    41.619161     4.023296   \n",
       "min       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "25%    1228.500000     5.000000   281.000000     0.000000     0.000000   \n",
       "50%    2457.000000     5.000000   431.000000     0.000000     0.000000   \n",
       "75%    3685.500000     5.000000   601.000000     0.000000     0.000000   \n",
       "max    4914.000000     5.000000  1064.000000  1952.000000   183.000000   \n",
       "\n",
       "        total_vote  score_pos_neg_diff  score_average_rating  \\\n",
       "count  4915.000000         4915.000000           4915.000000   \n",
       "mean      1.521465            1.100712              0.075468   \n",
       "std      44.123095           39.367949              0.256062   \n",
       "min       0.000000         -130.000000              0.000000   \n",
       "25%       0.000000            0.000000              0.000000   \n",
       "50%       0.000000            0.000000              0.000000   \n",
       "75%       0.000000            0.000000              0.000000   \n",
       "max    2020.000000         1884.000000              1.000000   \n",
       "\n",
       "       wilson_lower_bound  \n",
       "count         4915.000000  \n",
       "mean             0.020053  \n",
       "std              0.077187  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              0.957544  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "reviewerName            1\n",
       "overall                 0\n",
       "reviewText              1\n",
       "reviewTime              0\n",
       "day_diff                0\n",
       "helpful_yes             0\n",
       "helpful_no              0\n",
       "total_vote              0\n",
       "score_pos_neg_diff      0\n",
       "score_average_rating    0\n",
       "wilson_lower_bound      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Removing null values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4915, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4913, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Remove Unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hyoun Kim \"Faluzure\"</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>702</td>\n",
       "      <td>1952</td>\n",
       "      <td>68</td>\n",
       "      <td>2020</td>\n",
       "      <td>1884</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLee the Engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>2012-09-26</td>\n",
       "      <td>803</td>\n",
       "      <td>1428</td>\n",
       "      <td>77</td>\n",
       "      <td>1505</td>\n",
       "      <td>1351</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.936519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SkincareCEO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>579</td>\n",
       "      <td>1568</td>\n",
       "      <td>126</td>\n",
       "      <td>1694</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>0.912139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Customer \"Kelly\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If your card gets hot enough to be painful, it...</td>\n",
       "      <td>2012-02-09</td>\n",
       "      <td>1033</td>\n",
       "      <td>422</td>\n",
       "      <td>73</td>\n",
       "      <td>495</td>\n",
       "      <td>349</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.818577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerName  overall  \\\n",
       "0     Hyoun Kim \"Faluzure\"      5.0   \n",
       "1        NLee the Engineer      5.0   \n",
       "2              SkincareCEO      1.0   \n",
       "3  Amazon Customer \"Kelly\"      1.0   \n",
       "\n",
       "                                          reviewText  reviewTime  day_diff  \\\n",
       "0  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...  2013-01-05       702   \n",
       "1  I have tested dozens of SDHC and micro-SDHC ca...  2012-09-26       803   \n",
       "2  NOTE:  please read the last update (scroll to ...  2013-05-08       579   \n",
       "3  If your card gets hot enough to be painful, it...  2012-02-09      1033   \n",
       "\n",
       "   helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "0         1952          68        2020                1884   \n",
       "1         1428          77        1505                1351   \n",
       "2         1568         126        1694                1442   \n",
       "3          422          73         495                 349   \n",
       "\n",
       "   score_average_rating  wilson_lower_bound  \n",
       "0              0.966337            0.957544  \n",
       "1              0.948837            0.936519  \n",
       "2              0.925620            0.912139  \n",
       "3              0.852525            0.818577  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.drop(columns=['Unnamed: 0'],axis=1,inplace=True)\n",
    "review_df = review_df.sort_values(ascending=False,by='wilson_lower_bound')\n",
    "review_df = review_df.reset_index(drop=True)\n",
    "review_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "5.0    3921\n",
       "4.0     526\n",
       "1.0     244\n",
       "3.0     142\n",
       "2.0      80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>0.936519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>0.912139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText  \\\n",
       "0      5.0  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...   \n",
       "1      5.0  I have tested dozens of SDHC and micro-SDHC ca...   \n",
       "2      1.0  NOTE:  please read the last update (scroll to ...   \n",
       "\n",
       "   wilson_lower_bound  \n",
       "0            0.957544  \n",
       "1            0.936519  \n",
       "2            0.912139  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final = review_df[['overall','reviewText','wilson_lower_bound']]\n",
    "review_df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Pre Process (Removing Noise Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of below Pre Process Function:\n",
    "    * Stop Words: Words like \"is\", \"for\", etc., will be removed since they are in the stopword list.\n",
    "    * Punctuation: Tokens like \"#\", \"@\", \".\", \"<\", \">\" are removed since they are punctuation.\n",
    "    * Digits: Tokens like \"99\" and \"34working\" are removed because they contain numbers.\n",
    "    * Case-insensitive Uniqueness: The function ensures words like \"Bye\" and \"bye\" are considered the same and are only kept once.\n",
    "    * Lemmatization: The words are lemmatized to their base form to make sure variations like \"working\" and \"work\" are treated consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Load SpaCy model (use 'en_core_web_sm' for English)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def pre_process(txt):\n",
    "    tokens = nlp(txt)\n",
    "    existed_tokens =set()\n",
    "    filtered_tokens =[]\n",
    "\n",
    "    # Filter out:\n",
    "    # 1. Punctuation\n",
    "    # 2. Digits or alphanumeric tokens\n",
    "    # 3. Tokens containing non-alphabetic characters (e.g., Hello@, 34working)\n",
    "    # 4. Ensure case-insensitive uniqueness based on lemmatization\n",
    "    # 4. Stop words\n",
    "\n",
    "    for token in tokens:\n",
    "        # Lemmatize the token and convert to lowercase for uniformity\n",
    "        lemmatized_word = token.lemma_.lower()\n",
    "        if lemmatized_word not in existed_tokens and \\\n",
    "                token.text not in string.punctuation  and \\\n",
    "                not token.is_digit and \\\n",
    "                token.text.isalpha() and \\\n",
    "                token.text.lower() not in stop_words:\n",
    "            \n",
    "            filtered_tokens.append(token.text)\n",
    "            existed_tokens.add(lemmatized_word) # Track lemmatized word to ensure uniqueness\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['everything',\n",
       " 'everyone',\n",
       " 'Bye',\n",
       " 'correctly',\n",
       " 'testing',\n",
       " 'hospital',\n",
       " 'patient']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process(\"If # everything Hello@ everyone . Bye 99 is 34working correctly, < this testing in hospital for patient >  bye> EveryOne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets apply above Pre Process function on Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall               float64\n",
       "reviewText             object\n",
       "wilson_lower_bound    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_final['reviewText_after_general_pre_process'] =review_df_final['reviewText'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build another way of Pre Process function with pre trained BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Below function purpose is same as above pre process function however we are using Bert Tokenizer Model which is useful for large dataset\n",
    "and also improve performance\n",
    "'''\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "import nltk\n",
    "\n",
    "# Load the pre-trained BERT tokenizer once\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "stop_words_list = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def pre_process_with_bert(text):\n",
    "    # Tokenize into sub words\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Remove stop words and punctuation and numbers in one go\n",
    "    tokens =[token.strip() for token in tokens if token not in stop_words_list and \\\n",
    "                                                  token not in string.punctuation and \\\n",
    "                                                         token.isalpha() and \\\n",
    "                                                        not token.isdigit()\n",
    "                                                        ]\n",
    " \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['everything',\n",
       " 'working',\n",
       " 'hello',\n",
       " 'everyone',\n",
       " 'bye',\n",
       " 'correctly',\n",
       " 'testing',\n",
       " 'hospital',\n",
       " 'patient',\n",
       " 'bye',\n",
       " 'everyone']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process_with_bert(\"If # everything working Hello@ everyone . Bye 99 is 34working correctly, < this testing in hospital for patient >  bye> EveryOne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_final['reviewText_after_bert_pre_process'] = review_df_final['reviewText'].apply(pre_process_with_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "      <th>reviewText_after_general_pre_process</th>\n",
       "      <th>reviewText_after_bert_pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>0.957544</td>\n",
       "      <td>[UPDATE, lovely, wife, bought, Samsung, Galaxy...</td>\n",
       "      <td>[update, lovely, wife, bought, samsung, galaxy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>0.936519</td>\n",
       "      <td>[tested, dozens, SDHC, micro, cards, One, dist...</td>\n",
       "      <td>[tested, dozens, sd, micro, sd, cards, one, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>0.912139</td>\n",
       "      <td>[NOTE, please, read, last, update, scroll, bot...</td>\n",
       "      <td>[note, please, read, last, update, scroll, bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>If your card gets hot enough to be painful, it...</td>\n",
       "      <td>0.818577</td>\n",
       "      <td>[card, gets, hot, enough, painful, defective, ...</td>\n",
       "      <td>[card, gets, hot, enough, painful, defective, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Sandisk announcement of the first 128GB micro ...</td>\n",
       "      <td>0.808109</td>\n",
       "      <td>[Sandisk, announcement, first, GB, micro, SD, ...</td>\n",
       "      <td>[sand, announcement, first, micro, sd, took, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText  \\\n",
       "0      5.0  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...   \n",
       "1      5.0  I have tested dozens of SDHC and micro-SDHC ca...   \n",
       "2      1.0  NOTE:  please read the last update (scroll to ...   \n",
       "3      1.0  If your card gets hot enough to be painful, it...   \n",
       "4      5.0  Sandisk announcement of the first 128GB micro ...   \n",
       "\n",
       "   wilson_lower_bound               reviewText_after_general_pre_process  \\\n",
       "0            0.957544  [UPDATE, lovely, wife, bought, Samsung, Galaxy...   \n",
       "1            0.936519  [tested, dozens, SDHC, micro, cards, One, dist...   \n",
       "2            0.912139  [NOTE, please, read, last, update, scroll, bot...   \n",
       "3            0.818577  [card, gets, hot, enough, painful, defective, ...   \n",
       "4            0.808109  [Sandisk, announcement, first, GB, micro, SD, ...   \n",
       "\n",
       "                   reviewText_after_bert_pre_process  \n",
       "0  [update, lovely, wife, bought, samsung, galaxy...  \n",
       "1  [tested, dozens, sd, micro, sd, cards, one, di...  \n",
       "2  [note, please, read, last, update, scroll, bot...  \n",
       "3  [card, gets, hot, enough, painful, defective, ...  \n",
       "4  [sand, announcement, first, micro, sd, took, i...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing is completed, now its time to create Vector \n",
    "### In this case, we use word2vec model for creating embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Now, train the Word2Vec model on the list of tokenized sentences\n",
    "word2vec_model = Word2Vec(sentences=review_df_final['reviewText_after_bert_pre_process'],\n",
    "                           vector_size=100,  # size of the word vectors\n",
    "                           window=5,         # the maximum distance between a target word and its context word\n",
    "                           min_count=2,      # ignore words with a total frequency lower than this\n",
    "                           workers=4)        # number of CPU cores to use for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model for future use\n",
    "word2vec_model.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('last', 0.999125599861145),\n",
       " ('days', 0.9990836381912231),\n",
       " ('contacted', 0.9989287853240967),\n",
       " ('decided', 0.9987048506736755),\n",
       " ('received', 0.9986220002174377)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('update',topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of words in the vocabulary\n",
    "vocab_list = list(word2vec_model.wv.index_to_key)\n",
    "print(len(vocab_list))\n",
    "word2vec_model.wv['update'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Sentence Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why create sentence vectors?\n",
    "    * The reason for creating sentence vectors is to represent the entire sentence as a single, fixed-length vector. Word embeddings (like the ones learned by Word2Vec) represent individual words, but they don't provide an immediate way to understand the meaning of an entire sentence.\n",
    "    * Here's the flow:\n",
    "\n",
    "        ** Word2Vec Model: Each word in your vocabulary has a corresponding vector representation.\n",
    "        ** Sentence Vector: A sentence is composed of multiple words. Therefore, the sentence vector can be computed by averaging (or performing other aggregation methods) the word vectors of all words in the sentence.\n",
    "### Do you need to create sentence vectors?\n",
    "    * Yes, you still need to create sentence vectors if your goal is to represent an entire sentence as a feature for downstream tasks (like sentiment analysis). The Word2Vec model provides word-level embeddings, but for most machine learning tasks, you need a single vector to represent a sentence. Simply using Word2Vec directly on review_df_final['reviewText_after_bert_pre_process'] would give you word embeddings, but not sentence embeddings.\n",
    "\n",
    "    * The below function get_sentence_vector created is computing the sentence vector by averaging the word vectors for each word in the sentence. This is a common technique known as **\"mean pooling\"** or \"average word vectors\", and it allows you to summarize the semantic meaning of a sentence in a fixed-length vector, which can then be used for classification or other tasks.\n",
    "\n",
    "### Is it necessary to average the word vectors?\n",
    "    * Yes, because Word2Vec learns word-level representations, so when you want to use a Word2Vec model for a sentence, you need to aggregate the word vectors. There are several ways to do this, but the simplest and most commonly used approach is averaging the word vectors for all the words in the sentence, which is exactly what you're doing with np.mean(word_vectors, axis=0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(tokens,model):\n",
    "    word_vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(100)\n",
    "    \n",
    "    return np.mean(word_vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_final['sentence_vector'] = review_df_final['reviewText_after_bert_pre_process'].apply(lambda tokens:get_sentence_vector(tokens,word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final['sentence_vector'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(review_df_final['sentence_vector'])\n",
    "y = review_df_final['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3930, 100) (983, 100) (3930,) (983,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Now Initialize and Build ML Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Apply Random Forest Method\n",
    "    * This classifier is a popular machine learning algorithm used for both classification tasks (like sentiment analysis, fraud detection, etc.) and regression tasks. It's based on the Random Forest algorithm, which is an ensemble learning method that combines multiple decision trees to improve the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,            # Number of trees in the forest\n",
    "    criterion='entropy',         # Using 'entropy' to measure the quality of splits\n",
    "    max_depth=10,                # Maximum depth of each tree\n",
    "    min_samples_split=4,         # Minimum number of samples to split an internal node\n",
    "    min_samples_leaf=2,          # Minimum number of samples at a leaf node\n",
    "    max_features='sqrt',         # Number of features to consider at each split\n",
    "    random_state=42,             # For reproducibility\n",
    "    n_jobs=-1,                   # Use all processors\n",
    "    oob_score=True               # Use out-of-bag samples to estimate generalization accuracy\n",
    ")\n",
    "\n",
    "\n",
    "rf_classifier.fit(X_train,y_train)\n",
    "\n",
    "# Save the model using joblib\n",
    "joblib.dump(rf_classifier,'random_forest_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5. 5. 5. 5.]\n",
      "2346    5.0\n",
      "2555    5.0\n",
      "691     5.0\n",
      "3908    4.0\n",
      "2486    5.0\n",
      "Name: overall, dtype: float64\n",
      "accuracy of Random Forest Model is 0.8047\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "print(y_pred_rf[:5])\n",
    "print(y_test[:5])\n",
    "accuracy_rf = accuracy_score(y_test,y_pred_rf)\n",
    "print(f\"accuracy of Random Forest Model is {accuracy_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Combining all Classifier Models at One go and check accuracy for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3930, 100) (983, 100) (3930,) (983,)\n",
      "name is Random Forest and classifier is RandomForestClassifier(random_state=42)\n",
      "name is AdaBoost Classifier and classifier is AdaBoostClassifier(n_estimators=100, random_state=42)\n",
      "name is GradientBoosting Classifier and classifier is GradientBoostingClassifier(random_state=42)\n",
      "name is SVC and classifier is SVC(kernel='linear', random_state=42)\n",
      "name is Logistic Regression and classifier is LogisticRegression(max_iter=1000, random_state=42)\n",
      "name is MLP Classifier and classifier is MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)\n",
      "Model name is Random Forest and its accuracy is 0.8036622583926755\n",
      "Model name is AdaBoost Classifier and its accuracy is 0.7843336724313327\n",
      "Model name is GradientBoosting Classifier and its accuracy is 0.7995930824008138\n",
      "Model name is SVC and its accuracy is 0.8067141403865717\n",
      "Model name is Logistic Regression and its accuracy is 0.8097660223804679\n",
      "Model name is MLP Classifier and its accuracy is 0.8087487283825026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Initialize Classifiers\n",
    "\n",
    "classifiers ={\n",
    "    'Random Forest':RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "    'AdaBoost Classifier':AdaBoostClassifier(random_state=42,n_estimators=100),\n",
    "    'GradientBoosting Classifier':GradientBoostingClassifier(random_state=42,n_estimators=100),\n",
    "    'SVC':SVC(kernel='linear', random_state=42),\n",
    "    'Logistic Regression':LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'MLP Classifier':MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)\n",
    "\n",
    "}\n",
    "\n",
    "# Train and Evaluate Each Classifier\n",
    "\n",
    "results={}\n",
    "for name,classif in classifiers.items():\n",
    "    print(f\"name is {name} and classifier is {classif}\")\n",
    "\n",
    "    classif.fit(X_train,y_train)\n",
    "    y_pred = classif.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    results[name]=accuracy\n",
    "\n",
    "# Print accuracy results\n",
    "for name,accuracy in results.items():\n",
    "    print(f\"Model name is {name} and its accuracy is {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
