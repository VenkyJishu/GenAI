{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import openpyxl\n",
    "import nltk\n",
    "from bs4 import BeautifulSoup\n",
    "import sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.py', 'amazon_reviews.csv', 'IMDB_Dataset.xlsx']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.listdir(\"../Datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>No issues.</td>\n",
       "      <td>2014-07-23</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0mie</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Purchased this for my device, it worked as adv...</td>\n",
       "      <td>2013-10-25</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1K3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>it works as expected. I should have sprung for...</td>\n",
       "      <td>2012-12-23</td>\n",
       "      <td>715</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1m2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>This think has worked out great.Had a diff. br...</td>\n",
       "      <td>2013-11-21</td>\n",
       "      <td>382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 reviewerName  overall  \\\n",
       "0           0          NaN      4.0   \n",
       "1           1         0mie      5.0   \n",
       "2           2          1K3      4.0   \n",
       "3           3          1m2      5.0   \n",
       "\n",
       "                                          reviewText  reviewTime  day_diff  \\\n",
       "0                                         No issues.  2014-07-23       138   \n",
       "1  Purchased this for my device, it worked as adv...  2013-10-25       409   \n",
       "2  it works as expected. I should have sprung for...  2012-12-23       715   \n",
       "3  This think has worked out great.Had a diff. br...  2013-11-21       382   \n",
       "\n",
       "   helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "0            0           0           0                   0   \n",
       "1            0           0           0                   0   \n",
       "2            0           0           0                   0   \n",
       "3            0           0           0                   0   \n",
       "\n",
       "   score_average_rating  wilson_lower_bound  \n",
       "0                   0.0                 0.0  \n",
       "1                   0.0                 0.0  \n",
       "2                   0.0                 0.0  \n",
       "3                   0.0                 0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_csv(\"../Datasets/amazon_reviews.csv\")\n",
    "review_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4915, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                int64\n",
       "reviewerName             object\n",
       "overall                 float64\n",
       "reviewText               object\n",
       "reviewTime               object\n",
       "day_diff                  int64\n",
       "helpful_yes               int64\n",
       "helpful_no                int64\n",
       "total_vote                int64\n",
       "score_pos_neg_diff        int64\n",
       "score_average_rating    float64\n",
       "wilson_lower_bound      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>overall</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "      <td>4915.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2457.000000</td>\n",
       "      <td>4.587589</td>\n",
       "      <td>437.367040</td>\n",
       "      <td>1.311089</td>\n",
       "      <td>0.210376</td>\n",
       "      <td>1.521465</td>\n",
       "      <td>1.100712</td>\n",
       "      <td>0.075468</td>\n",
       "      <td>0.020053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1418.982617</td>\n",
       "      <td>0.996845</td>\n",
       "      <td>209.439871</td>\n",
       "      <td>41.619161</td>\n",
       "      <td>4.023296</td>\n",
       "      <td>44.123095</td>\n",
       "      <td>39.367949</td>\n",
       "      <td>0.256062</td>\n",
       "      <td>0.077187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-130.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1228.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>281.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2457.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>431.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3685.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4914.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1064.000000</td>\n",
       "      <td>1952.000000</td>\n",
       "      <td>183.000000</td>\n",
       "      <td>2020.000000</td>\n",
       "      <td>1884.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0      overall     day_diff  helpful_yes   helpful_no  \\\n",
       "count  4915.000000  4915.000000  4915.000000  4915.000000  4915.000000   \n",
       "mean   2457.000000     4.587589   437.367040     1.311089     0.210376   \n",
       "std    1418.982617     0.996845   209.439871    41.619161     4.023296   \n",
       "min       0.000000     1.000000     1.000000     0.000000     0.000000   \n",
       "25%    1228.500000     5.000000   281.000000     0.000000     0.000000   \n",
       "50%    2457.000000     5.000000   431.000000     0.000000     0.000000   \n",
       "75%    3685.500000     5.000000   601.000000     0.000000     0.000000   \n",
       "max    4914.000000     5.000000  1064.000000  1952.000000   183.000000   \n",
       "\n",
       "        total_vote  score_pos_neg_diff  score_average_rating  \\\n",
       "count  4915.000000         4915.000000           4915.000000   \n",
       "mean      1.521465            1.100712              0.075468   \n",
       "std      44.123095           39.367949              0.256062   \n",
       "min       0.000000         -130.000000              0.000000   \n",
       "25%       0.000000            0.000000              0.000000   \n",
       "50%       0.000000            0.000000              0.000000   \n",
       "75%       0.000000            0.000000              0.000000   \n",
       "max    2020.000000         1884.000000              1.000000   \n",
       "\n",
       "       wilson_lower_bound  \n",
       "count         4915.000000  \n",
       "mean             0.020053  \n",
       "std              0.077187  \n",
       "min              0.000000  \n",
       "25%              0.000000  \n",
       "50%              0.000000  \n",
       "75%              0.000000  \n",
       "max              0.957544  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0              0\n",
       "reviewerName            1\n",
       "overall                 0\n",
       "reviewText              1\n",
       "reviewTime              0\n",
       "day_diff                0\n",
       "helpful_yes             0\n",
       "helpful_no              0\n",
       "total_vote              0\n",
       "score_pos_neg_diff      0\n",
       "score_average_rating    0\n",
       "wilson_lower_bound      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Removing null values from dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4915, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4913, 12)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Remove Unwanted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>day_diff</th>\n",
       "      <th>helpful_yes</th>\n",
       "      <th>helpful_no</th>\n",
       "      <th>total_vote</th>\n",
       "      <th>score_pos_neg_diff</th>\n",
       "      <th>score_average_rating</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hyoun Kim \"Faluzure\"</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>2013-01-05</td>\n",
       "      <td>702</td>\n",
       "      <td>1952</td>\n",
       "      <td>68</td>\n",
       "      <td>2020</td>\n",
       "      <td>1884</td>\n",
       "      <td>0.966337</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NLee the Engineer</td>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>2012-09-26</td>\n",
       "      <td>803</td>\n",
       "      <td>1428</td>\n",
       "      <td>77</td>\n",
       "      <td>1505</td>\n",
       "      <td>1351</td>\n",
       "      <td>0.948837</td>\n",
       "      <td>0.936519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SkincareCEO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>579</td>\n",
       "      <td>1568</td>\n",
       "      <td>126</td>\n",
       "      <td>1694</td>\n",
       "      <td>1442</td>\n",
       "      <td>0.925620</td>\n",
       "      <td>0.912139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Customer \"Kelly\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>If your card gets hot enough to be painful, it...</td>\n",
       "      <td>2012-02-09</td>\n",
       "      <td>1033</td>\n",
       "      <td>422</td>\n",
       "      <td>73</td>\n",
       "      <td>495</td>\n",
       "      <td>349</td>\n",
       "      <td>0.852525</td>\n",
       "      <td>0.818577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              reviewerName  overall  \\\n",
       "0     Hyoun Kim \"Faluzure\"      5.0   \n",
       "1        NLee the Engineer      5.0   \n",
       "2              SkincareCEO      1.0   \n",
       "3  Amazon Customer \"Kelly\"      1.0   \n",
       "\n",
       "                                          reviewText  reviewTime  day_diff  \\\n",
       "0  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...  2013-01-05       702   \n",
       "1  I have tested dozens of SDHC and micro-SDHC ca...  2012-09-26       803   \n",
       "2  NOTE:  please read the last update (scroll to ...  2013-05-08       579   \n",
       "3  If your card gets hot enough to be painful, it...  2012-02-09      1033   \n",
       "\n",
       "   helpful_yes  helpful_no  total_vote  score_pos_neg_diff  \\\n",
       "0         1952          68        2020                1884   \n",
       "1         1428          77        1505                1351   \n",
       "2         1568         126        1694                1442   \n",
       "3          422          73         495                 349   \n",
       "\n",
       "   score_average_rating  wilson_lower_bound  \n",
       "0              0.966337            0.957544  \n",
       "1              0.948837            0.936519  \n",
       "2              0.925620            0.912139  \n",
       "3              0.852525            0.818577  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.drop(columns=['Unnamed: 0'],axis=1,inplace=True)\n",
    "review_df = review_df.sort_values(ascending=False,by='wilson_lower_bound')\n",
    "review_df = review_df.reset_index(drop=True)\n",
    "review_df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall\n",
       "5.0    3921\n",
       "4.0     526\n",
       "1.0     244\n",
       "3.0     142\n",
       "2.0      80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>0.957544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>0.936519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>0.912139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText  \\\n",
       "0      5.0  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...   \n",
       "1      5.0  I have tested dozens of SDHC and micro-SDHC ca...   \n",
       "2      1.0  NOTE:  please read the last update (scroll to ...   \n",
       "\n",
       "   wilson_lower_bound  \n",
       "0            0.957544  \n",
       "1            0.936519  \n",
       "2            0.912139  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final = review_df[['overall','reviewText','wilson_lower_bound']]\n",
    "review_df_final.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Pre Process (Removing Noise Data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explanation of below Pre Process Function:\n",
    "    * Stop Words: Words like \"is\", \"for\", etc., will be removed since they are in the stopword list.\n",
    "    * Punctuation: Tokens like \"#\", \"@\", \".\", \"<\", \">\" are removed since they are punctuation.\n",
    "    * Digits: Tokens like \"99\" and \"34working\" are removed because they contain numbers.\n",
    "    * Case-insensitive Uniqueness: The function ensures words like \"Bye\" and \"bye\" are considered the same and are only kept once.\n",
    "    * Lemmatization: The words are lemmatized to their base form to make sure variations like \"working\" and \"work\" are treated consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import spacy\n",
    "\n",
    "\n",
    "# Load SpaCy model (use 'en_core_web_sm' for English)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def pre_process(txt):\n",
    "    tokens = nlp(txt)\n",
    "    existed_tokens =set()\n",
    "    filtered_tokens =[]\n",
    "\n",
    "    # Filter out:\n",
    "    # 1. Punctuation\n",
    "    # 2. Digits or alphanumeric tokens\n",
    "    # 3. Tokens containing non-alphabetic characters (e.g., Hello@, 34working)\n",
    "    # 4. Ensure case-insensitive uniqueness based on lemmatization\n",
    "    # 4. Stop words\n",
    "\n",
    "    for token in tokens:\n",
    "        # Lemmatize the token and convert to lowercase for uniformity\n",
    "        lemmatized_word = token.lemma_.lower()\n",
    "        if lemmatized_word not in existed_tokens and \\\n",
    "                token.text not in string.punctuation  and \\\n",
    "                not token.is_digit and \\\n",
    "                token.text.isalpha() and \\\n",
    "                token.text.lower() not in stop_words:\n",
    "            \n",
    "            filtered_tokens.append(token.text)\n",
    "            existed_tokens.add(lemmatized_word) # Track lemmatized word to ensure uniqueness\n",
    "    \n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['everything',\n",
       " 'everyone',\n",
       " 'Bye',\n",
       " 'correctly',\n",
       " 'testing',\n",
       " 'hospital',\n",
       " 'patient']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process(\"If # everything Hello@ everyone . Bye 99 is 34working correctly, < this testing in hospital for patient >  bye> EveryOne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets apply above Pre Process function on Reviews Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "overall               float64\n",
       "reviewText             object\n",
       "wilson_lower_bound    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_final['reviewText_after_general_pre_process'] =review_df_final['reviewText'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build another way of Pre Process function with pre trained BERT Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Below function purpose is same as above pre process function however we are using Bert Tokenizer Model which is useful for large dataset\n",
    "and also improve performance\n",
    "'''\n",
    "\n",
    "from transformers import BertTokenizer\n",
    "import nltk\n",
    "\n",
    "# Load the pre-trained BERT tokenizer once\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "stop_words_list = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "def pre_process_with_bert(text):\n",
    "    # Tokenize into sub words\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "\n",
    "    # Remove stop words and punctuation and numbers in one go\n",
    "    tokens =[token.strip() for token in tokens if token not in stop_words_list and \\\n",
    "                                                  token not in string.punctuation and \\\n",
    "                                                         token.isalpha() and \\\n",
    "                                                        not token.isdigit()\n",
    "                                                        ]\n",
    " \n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['everything',\n",
       " 'working',\n",
       " 'hello',\n",
       " 'everyone',\n",
       " 'bye',\n",
       " 'correctly',\n",
       " 'testing',\n",
       " 'hospital',\n",
       " 'patient',\n",
       " 'bye',\n",
       " 'everyone']"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_process_with_bert(\"If # everything working Hello@ everyone . Bye 99 is 34working correctly, < this testing in hospital for patient >  bye> EveryOne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_final['reviewText_after_bert_pre_process'] = review_df_final['reviewText'].apply(pre_process_with_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>wilson_lower_bound</th>\n",
       "      <th>reviewText_after_general_pre_process</th>\n",
       "      <th>reviewText_after_bert_pre_process</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>[[ UPDATE - 6/19/2014 ]]So my lovely wife boug...</td>\n",
       "      <td>0.957544</td>\n",
       "      <td>[UPDATE, lovely, wife, bought, Samsung, Galaxy...</td>\n",
       "      <td>[update, lovely, wife, bought, samsung, galaxy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>I have tested dozens of SDHC and micro-SDHC ca...</td>\n",
       "      <td>0.936519</td>\n",
       "      <td>[tested, dozens, SDHC, micro, cards, One, dist...</td>\n",
       "      <td>[tested, dozens, sd, micro, sd, cards, one, di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NOTE:  please read the last update (scroll to ...</td>\n",
       "      <td>0.912139</td>\n",
       "      <td>[NOTE, please, read, last, update, scroll, bot...</td>\n",
       "      <td>[note, please, read, last, update, scroll, bot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>If your card gets hot enough to be painful, it...</td>\n",
       "      <td>0.818577</td>\n",
       "      <td>[card, gets, hot, enough, painful, defective, ...</td>\n",
       "      <td>[card, gets, hot, enough, painful, defective, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Sandisk announcement of the first 128GB micro ...</td>\n",
       "      <td>0.808109</td>\n",
       "      <td>[Sandisk, announcement, first, GB, micro, SD, ...</td>\n",
       "      <td>[sand, announcement, first, micro, sd, took, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall                                         reviewText  \\\n",
       "0      5.0  [[ UPDATE - 6/19/2014 ]]So my lovely wife boug...   \n",
       "1      5.0  I have tested dozens of SDHC and micro-SDHC ca...   \n",
       "2      1.0  NOTE:  please read the last update (scroll to ...   \n",
       "3      1.0  If your card gets hot enough to be painful, it...   \n",
       "4      5.0  Sandisk announcement of the first 128GB micro ...   \n",
       "\n",
       "   wilson_lower_bound               reviewText_after_general_pre_process  \\\n",
       "0            0.957544  [UPDATE, lovely, wife, bought, Samsung, Galaxy...   \n",
       "1            0.936519  [tested, dozens, SDHC, micro, cards, One, dist...   \n",
       "2            0.912139  [NOTE, please, read, last, update, scroll, bot...   \n",
       "3            0.818577  [card, gets, hot, enough, painful, defective, ...   \n",
       "4            0.808109  [Sandisk, announcement, first, GB, micro, SD, ...   \n",
       "\n",
       "                   reviewText_after_bert_pre_process  \n",
       "0  [update, lovely, wife, bought, samsung, galaxy...  \n",
       "1  [tested, dozens, sd, micro, sd, cards, one, di...  \n",
       "2  [note, please, read, last, update, scroll, bot...  \n",
       "3  [card, gets, hot, enough, painful, defective, ...  \n",
       "4  [sand, announcement, first, micro, sd, took, i...  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Initialize Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre Processing is completed, now its time to create Vector \n",
    "### In this case, we use word2vec model for creating embedding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Now, train the Word2Vec model on the list of tokenized sentences\n",
    "word2vec_model = Word2Vec(sentences=review_df_final['reviewText_after_bert_pre_process'],\n",
    "                           vector_size=100,  # size of the word vectors\n",
    "                           window=5,         # the maximum distance between a target word and its context word\n",
    "                           min_count=2,      # ignore words with a total frequency lower than this\n",
    "                           workers=4)        # number of CPU cores to use for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model for future use\n",
    "word2vec_model.save(\"word2vec_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('returned', 0.9989586472511292),\n",
       " ('received', 0.9989252686500549),\n",
       " ('replace', 0.9984667301177979),\n",
       " ('sent', 0.9983127117156982),\n",
       " ('ago', 0.9982167482376099)]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar('update',topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3527\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of words in the vocabulary\n",
    "vocab_list = list(word2vec_model.wv.index_to_key)\n",
    "print(len(vocab_list))\n",
    "word2vec_model.wv['update'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Sentence Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(tokens,model):\n",
    "    word_vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(100)\n",
    "    \n",
    "    return np.mean(word_vectors,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_final['sentence_vector'] = review_df_final['reviewText_after_bert_pre_process'].apply(lambda tokens:get_sentence_vector(tokens,word2vec_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df_final['sentence_vector'][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Split into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(review_df_final['sentence_vector'])\n",
    "y = review_df_final['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3930, 100) (983, 100) (3930,) (983,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Now Initialize and Build ML Model for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Apply Random Forest Method\n",
    "    * This classifier is a popular machine learning algorithm used for both classification tasks (like sentiment analysis, fraud detection, etc.) and regression tasks. It's based on the Random Forest algorithm, which is an ensemble learning method that combines multiple decision trees to improve the overall performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=2,\n",
       "                       min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
       "                       oob_score=True, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, min_samples_leaf=2,\n",
       "                       min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
       "                       oob_score=True, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=10, min_samples_leaf=2,\n",
       "                       min_samples_split=4, n_estimators=200, n_jobs=-1,\n",
       "                       oob_score=True, random_state=42)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=200,            # Number of trees in the forest\n",
    "    criterion='entropy',         # Using 'entropy' to measure the quality of splits\n",
    "    max_depth=10,                # Maximum depth of each tree\n",
    "    min_samples_split=4,         # Minimum number of samples to split an internal node\n",
    "    min_samples_leaf=2,          # Minimum number of samples at a leaf node\n",
    "    max_features='sqrt',         # Number of features to consider at each split\n",
    "    random_state=42,             # For reproducibility\n",
    "    n_jobs=-1,                   # Use all processors\n",
    "    oob_score=True               # Use out-of-bag samples to estimate generalization accuracy\n",
    ")\n",
    "\n",
    "\n",
    "rf_classifier.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5. 5. 5. 5. 5.]\n",
      "2346    5.0\n",
      "2555    5.0\n",
      "691     5.0\n",
      "3908    4.0\n",
      "2486    5.0\n",
      "Name: overall, dtype: float64\n",
      "accuracy of Random Forest Model is 0.8087\n"
     ]
    }
   ],
   "source": [
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "print(y_pred_rf[:5])\n",
    "print(y_test[:5])\n",
    "accuracy_rf = accuracy_score(y_test,y_pred_rf)\n",
    "print(f\"accuracy of Random Forest Model is {accuracy_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Combining all Classifier Models at One go and check accuracy for each one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3930, 100) (983, 100) (3930,) (983,)\n",
      "name is Random Forest and classifier is RandomForestClassifier(random_state=42)\n",
      "name is AdaBoost Classifier and classifier is AdaBoostClassifier(n_estimators=100, random_state=42)\n",
      "name is GradientBoosting Classifier and classifier is GradientBoostingClassifier(random_state=42)\n",
      "name is SVC and classifier is SVC(kernel='linear', random_state=42)\n",
      "name is Logistic Regression and classifier is LogisticRegression(max_iter=1000, random_state=42)\n",
      "name is MLP Classifier and classifier is MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)\n",
      "Model name is Random Forest and its accuracy is 0.8077314343845371\n",
      "Model name is AdaBoost Classifier and its accuracy is 0.7934893184130214\n",
      "Model name is GradientBoosting Classifier and its accuracy is 0.8006103763987793\n",
      "Model name is SVC and its accuracy is 0.8067141403865717\n",
      "Model name is Logistic Regression and its accuracy is 0.8087487283825026\n",
      "Model name is MLP Classifier and its accuracy is 0.8087487283825026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "# Initialize Classifiers\n",
    "\n",
    "classifiers ={\n",
    "    'Random Forest':RandomForestClassifier(n_estimators=100,random_state=42),\n",
    "    'AdaBoost Classifier':AdaBoostClassifier(random_state=42,n_estimators=100),\n",
    "    'GradientBoosting Classifier':GradientBoostingClassifier(random_state=42,n_estimators=100),\n",
    "    'SVC':SVC(kernel='linear', random_state=42),\n",
    "    'Logistic Regression':LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'MLP Classifier':MLPClassifier(hidden_layer_sizes=(50,), max_iter=1000, random_state=42)\n",
    "\n",
    "}\n",
    "\n",
    "# Train and Evaluate Each Classifier\n",
    "\n",
    "results={}\n",
    "for name,classif in classifiers.items():\n",
    "    print(f\"name is {name} and classifier is {classif}\")\n",
    "\n",
    "    classif.fit(X_train,y_train)\n",
    "    y_pred = classif.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test,y_pred)\n",
    "    results[name]=accuracy\n",
    "\n",
    "# Print accuracy results\n",
    "for name,accuracy in results.items():\n",
    "    print(f\"Model name is {name} and its accuracy is {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
